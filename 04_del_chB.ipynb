{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make apo version for enzdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/home/pleung/projects/bistable_bundle/r4/helix_binders\n",
      "dig28\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "# python internal\n",
    "import collections\n",
    "import copy\n",
    "import gc\n",
    "from glob import glob\n",
    "import h5py\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import socket\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# conda/pip\n",
    "import dask\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# special packages on the DIGS\n",
    "import py3Dmol\n",
    "import pymol\n",
    "import pyrosetta\n",
    "\n",
    "# notebook magic\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(os.getcwd())\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make function to delete chB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosetta.distributed.packed_pose.core import PackedPose\n",
    "from pyrosetta.distributed import requires_init\n",
    "from typing import *\n",
    "\n",
    "\n",
    "@requires_init\n",
    "def del_chB(packed_pose_in=None, **kwargs) -> PackedPose:\n",
    "    \"\"\"\"\"\"\n",
    "    import bz2\n",
    "    import pyrosetta\n",
    "    import pyrosetta.distributed.io as io\n",
    "    from pyrosetta.distributed.tasks.rosetta_scripts import (\n",
    "        SingleoutputRosettaScriptsTask,\n",
    "    )\n",
    "\n",
    "    if packed_pose_in == None:\n",
    "        file = kwargs[\"-s\"]\n",
    "        with open(file, \"rb\") as f:\n",
    "            ppose = io.pose_from_pdbstring(bz2.decompress(f.read()).decode())\n",
    "        scores = pyrosetta.distributed.cluster.get_scores_dict(file)[\"scores\"]\n",
    "    else:\n",
    "        raise RuntimeError(\"Need to supply an input\")\n",
    "\n",
    "    xml = \"\"\"\n",
    "    <ROSETTASCRIPTS>\n",
    "        <SCOREFXNS>\n",
    "        </SCOREFXNS>\n",
    "        <RESIDUE_SELECTORS>\n",
    "        </RESIDUE_SELECTORS>\n",
    "        <TASKOPERATIONS>\n",
    "        </TASKOPERATIONS>\n",
    "        <MOVERS>\n",
    "            <SwitchChainOrder name=\"delete\" chain_order=\"1\"/>\n",
    "        </MOVERS>\n",
    "        <PROTOCOLS>\n",
    "            <Add mover=\"delete\"/>\n",
    "        </PROTOCOLS>\n",
    "    </ROSETTASCRIPTS>\n",
    "    \"\"\"\n",
    "    delete = SingleoutputRosettaScriptsTask(xml)\n",
    "    chain1 = delete(packed_pose_in.pose.clone())\n",
    "    pose = io.to_pose(chain1)\n",
    "    for key, value in scores.items():\n",
    "        pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)\n",
    "    final_ppose = io.to_packed(pose)\n",
    "    return final_ppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup dask, set command line options, make tasks and submit to client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import logging\n",
    "import pwd\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "\n",
    "\n",
    "print(\"run the following from your local terminal:\")\n",
    "print(\n",
    "    f\"ssh -L 8000:localhost:8787 {pwd.getpwuid(os.getuid()).pw_name}@{socket.gethostname()}\"\n",
    ")\n",
    "\n",
    "\n",
    "def create_tasks(selected, options):\n",
    "    with open(selected, \"r\") as f:\n",
    "        for file in f:\n",
    "            tasks = {\"options\": \"\"}\n",
    "            tasks[\"extra_options\"] = options\n",
    "            tasks[\"-s\"] = file.rstrip()\n",
    "            yield tasks\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "selected = os.path.join(os.getcwd(), \"03_enumerate_loops/closed.list\")\n",
    "\n",
    "options = {\n",
    "    \"-out:level\": \"300\",\n",
    "    \"-holes:dalphaball\": \"/home/bcov/ppi/tutorial_build/main/source/external/DAlpahBall/DAlphaBall.gcc\",\n",
    "    \"-indexed_structure_store:fragment_store\": \"/net/databases/VALL_clustered/connect_chains/ss_grouped_vall_helix_shortLoop.h5\",\n",
    "}\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), \"04_del_chB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # configure SLURM cluster as a context manager\n",
    "    with SLURMCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        job_cpu=1,\n",
    "        memory=\"16GB\",\n",
    "        queue=\"long\",\n",
    "        walltime=\"23:30:00\",\n",
    "        death_timeout=120,\n",
    "        local_directory=\"$TMPDIR/dask\",\n",
    "        log_directory=\"/mnt/home/pleung/logs/slurm_logs\",\n",
    "        extra=[\"--lifetime\", \"23h\", \"--lifetime-stagger\", \"4m\"],\n",
    "    ) as cluster:\n",
    "        print(cluster.job_script())\n",
    "        # scale between 1-510 workers,\n",
    "        cluster.adapt(\n",
    "            minimum=1,\n",
    "            maximum=50,\n",
    "            wait_count=360,  # Number of consecutive times that a worker should be suggested for removal it is removed\n",
    "            interval=\"5s\",  # Time between checks\n",
    "        )\n",
    "        # setup a client to interact with the cluster as a context manager\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            PyRosettaCluster(\n",
    "                tasks=create_tasks(selected, options),\n",
    "                client=client,\n",
    "                scratch_dir=output_path,\n",
    "                output_path=output_path,\n",
    "            ).distribute(protocols=[del_chB])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phil (3.8.2)",
   "language": "python",
   "name": "phil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
